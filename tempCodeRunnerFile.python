import os
import glob
import cv2
import numpy as np
from retinaface import RetinaFace
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tqdm import tqdm

# Set GPU memory growth (optional, for TensorFlow)
import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)

# Function to extract and align face using RetinaFace
def extract_face_retinaface(frame):
    detections = RetinaFace.detect_faces(frame)
    if not detections:
        return None
    for key, face in detections.items():
        x1, y1, x2, y2 = face['facial_area']
        landmarks = face['landmarks']
        aligned_face = align_face(frame, landmarks)
        if aligned_face is not None:
            return cv2.resize(aligned_face, (128, 128))
    return None

# Align face based on eye landmarks
def align_face(frame, landmarks):
    left_eye = landmarks['left_eye']
    right_eye = landmarks['right_eye']
    dx, dy = right_eye[0] - left_eye[0], right_eye[1] - left_eye[1]
    angle = np.degrees(np.arctan2(dy, dx))
    center = tuple(np.mean([left_eye, right_eye], axis=0).astype(int))
    rot_matrix = cv2.getRotationMatrix2D(center, angle, scale=1.0)
    aligned_face = cv2.warpAffine(frame, rot_matrix, (frame.shape[1], frame.shape[0]))
    return aligned_face

# Process video to extract faces
def process_video(video_path, max_frames=100):
    cap = cv2.VideoCapture(video_path)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    indices = np.linspace(0, frame_count - 1, max_frames, dtype=int)
    faces = []
    for idx in tqdm(indices, desc=f"Processing {os.path.basename(video_path)}", leave=False):
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if not ret or frame is None:
            continue
        face = extract_face_retinaface(frame)
        if face is not None:
            faces.append(face)
    cap.release()
    return np.array(faces)

# Prepare dataset with progress percentage
def prepare_dataset(base_path, max_frames=100):
    video_paths, labels = [], []
    for label, folder in enumerate(['real', 'fake']):
        folder_path = os.path.join(base_path, folder)
        if not os.path.exists(folder_path):
            continue
        for video_file in glob.glob(os.path.join(folder_path, '*.mp4')):
            video_paths.append(video_file)
            labels.append(label)
    X, y = [], []
    for i, (path, label) in enumerate(tqdm(list(zip(video_paths, labels)), desc="Processing videos", unit="video")):
        faces = process_video(path, max_frames)
        if faces.shape[0] == 0:
            print(f"Skipped {path} (no valid faces)")
            continue
        for face in faces:
            X.append(face)
            y.append(label)
    return np.array(X), np.array(y)

# Build ResNet-50 model
def build_resnet_model(input_shape=(128, 128, 3)):
    base = ResNet50(include_top=False, input_shape=input_shape, weights='imagenet')
    x = GlobalAveragePooling2D()(base.output)
    x = Dropout(0.5)(x)
    out = Dense(2, activation='softmax')(x)
    model = Model(inputs=base.input, outputs=out)
    for layer in base.layers:
        layer.trainable = False
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

if __name__ == "__main__":
    base_path = r"C:\Users\Pavan\Downloads\FF++"  # Change to your dataset path
    print("Preparing dataset...")
    X, y = prepare_dataset(base_path, max_frames=100)
    if len(X) == 0:
        print("No data extracted. Check your dataset path and video files.")
    else:
        print("Dataset preparation complete.")
        X = X.astype('float32') / 255.0
        y_cat = to_categorical(y, num_classes=2)
        X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, stratify=y, random_state=42)
        print("Building model...")
        model = build_resnet_model(input_shape=(128, 128, 3))
        callbacks = [
            EarlyStopping(patience=3, restore_best_weights=True),
            ModelCheckpoint("best_resnet_face.h5", save_best_only=True)
        ]
        print("Training model...")
        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, callbacks=callbacks)
        print("Evaluating model...")
        loss, acc = model.evaluate(X_test, y_test)
        print(f"Test Accuracy: {acc:.4f}")